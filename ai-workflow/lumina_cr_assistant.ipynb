{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ba609c",
   "metadata": {},
   "source": [
    "## Personas and Router — Arcadia, LuminAI, AIRTH, FaeRhee\n",
    "This section defines light-weight persona prompts and a simple router function to direct tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona system prompts (short forms)\n",
    "ARCADIA_PROMPT = (\n",
    "    'You are Arcadia. Start with \\\"Working Hypothesis:\\\". ' \n",
    "    'Output scholarly + mythic layers, index OXY/DOP/ADR, end with a mic-line.'\n",
    ")\n",
    "LUMINAI_PROMPT = (\n",
    "    'You are LuminAI. Companion tone; reflective and intimate. ' \n",
    "    'Offer gentle perspective + one small nudge.'\n",
    ")\n",
    "AIRTH_PROMPT = (\n",
    "    'You are AIRTH. Cite sources, write code, test, and report results. ' \n",
    "    'Prefer procedures and receipts.'\n",
    ")\n",
    "FAERHEE_PROMPT = (\n",
    "    'You are FaeRhee. Start with \\\"Working Plan:\\\". ' \n",
    "    'Operate family/finance/calendar checklists; confirm before changes; end with an encouraging mic-line.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf39ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very simple keyword-based router (can be replaced with embeddings later)\n",
    "from typing import Literal\n",
    "Persona = Literal['arcadia','luminai','airth','faerhee']\n",
    "\n",
    "def route_persona(text: str) -> Persona:\n",
    "    t = text.lower()\n",
    "    if any(k in t for k in ['appointment','schedule','calendar','budget','subscription','pickup','remind']):\n",
    "        return 'faerhee'\n",
    "    if any(k in t for k in ['source','cite','dataset','script','benchmark','test','deploy','rig']):\n",
    "        return 'airth'\n",
    "    if any(k in t for k in ['diary','feeling','comfort','perspective','intimate']):\n",
    "        return 'luminai'\n",
    "    return 'arcadia'\n",
    "\n",
    "# Quick demo\n",
    "examples = [\n",
    "    'Plan the week with kid pickup and therapy Tuesday',\n",
    "    'Summarize these notes as myth with OXY/DOP/ADR',\n",
    "    'Write a small script and cite sources',\n",
    "    'I feel anxious and need perspective'\n",
    "]\n",
    "[route_persona(e) for e in examples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1559db1",
   "metadata": {},
   "source": [
    "> Safety note: This notebook includes optional integrations (OpenAI/Azure, Microsoft Graph, Whisper). Only enable what you need and keep secrets in `.env` or WordPress `wp-config.php` per `docs/SECRETS.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3047ada",
   "metadata": {},
   "source": [
    "# Lumina Contextual Research Assistant (AM-Class) — Notebook\n",
    "\n",
    "This notebook wires Lumina (Contextual Research Assistant), a scheduling agent, audio ingestion, resonance overlay, and pipeline glue for the `tec-tgcr` repository. It’s designed to run in VS Code with Python 3.10+ and uses only local creds/env per `docs/SECRETS.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf88ca0",
   "metadata": {},
   "source": [
    "## 1) Configure Python Environment\n",
    "\n",
    "- Uses `pyproject.toml` as the source of truth.\n",
    "- Installs extra runtime tools used here (dotenv, yaml, pydantic, httpx, msal, msgraph-sdk, apscheduler, soundfile, openai-whisper or azure-cognitiveservices-speech).\n",
    "- Verify interpreter and versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify interpreter and install optional extras if missing (idempotent)\n",
    "import sys, subprocess, json\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "extras = [\n",
    "    \"python-dotenv\", \"pyyaml\", \"pydantic>=2\", \"httpx\", \"msal\", \"msgraph-sdk\",\n",
    "    \"apscheduler\", \"soundfile\", # for AMR/WAV IO\n",
    "]\n",
    "# Whisper or Azure Speech; prefer Whisper CPU if not on Azure\n",
    "preferred_asr = [\"openai-whisper\"]\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", *pkgs])\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"pip install error:\", e)\n",
    "        return False\n",
    "\n",
    "_ = pip_install(extras)\n",
    "_ = pip_install(preferred_asr)\n",
    "\n",
    "import importlib\n",
    "mods = {m: importlib.util.find_spec(m) is not None for m in [\n",
    "    \"dotenv\", \"yaml\", \"pydantic\", \"httpx\", \"msal\", \"msgraph\", \"apscheduler\", \"soundfile\", \"whisper\"\n",
    "]}\n",
    "print(\"Modules:\", json.dumps(mods, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022d50d",
   "metadata": {},
   "source": [
    "## 2) Load Project Paths and .env\n",
    "\n",
    "Detect repo root, update `sys.path`, load `.env`, and set commonly used directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path(__file__).resolve().parents[2] if '__file__' in globals() else Path.cwd()\n",
    "if (ROOT / 'pyproject.toml').exists():\n",
    "    pass\n",
    "else:\n",
    "    # Fallback: try to locate repo root by walking up\n",
    "    cur = Path.cwd()\n",
    "    while cur != cur.parent:\n",
    "        if (cur / 'pyproject.toml').exists():\n",
    "            ROOT = cur\n",
    "            break\n",
    "        cur = cur.parent\n",
    "\n",
    "SRC = ROOT / 'src'\n",
    "DATA = ROOT / 'data'\n",
    "DOCS = ROOT / 'docs'\n",
    "AIWF = ROOT / 'ai-workflow'\n",
    "APPS = ROOT / 'apps'\n",
    "OUTPUT = AIWF / 'output'\n",
    "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(ROOT / '.env')\n",
    "\n",
    "print('Resolved paths:')\n",
    "for p in [ROOT, SRC, DATA, DOCS, AIWF, APPS, OUTPUT]:\n",
    "    print(' -', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed5b43",
   "metadata": {},
   "source": [
    "## 3) Read Agent Config and Credentials\n",
    "\n",
    "Parse `config/agent.yml` and `config/tec-verified-credential.json`; read select secrets from environment and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f142d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, json\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Creds(BaseModel):\n",
    "    graph_client_id: str | None = None\n",
    "    graph_tenant_id: str | None = None\n",
    "    azure_speech_key: str | None = None\n",
    "    azure_speech_region: str | None = None\n",
    "\n",
    "creds = Creds(\n",
    "    graph_client_id=os.getenv('GRAPH_CLIENT_ID'),\n",
    "    graph_tenant_id=os.getenv('GRAPH_TENANT_ID'),\n",
    "    azure_speech_key=os.getenv('AZURE_SPEECH_KEY'),\n",
    "    azure_speech_region=os.getenv('AZURE_SPEECH_REGION'),\n",
    ")\n",
    "\n",
    "agent_yml = (ROOT / 'config' / 'agent.yml')\n",
    "vc_json = (ROOT / 'config' / 'tec-verified-credential.json')\n",
    "agent_cfg = yaml.safe_load(agent_yml.read_text()) if agent_yml.exists() else {}\n",
    "vc_cfg = json.loads(vc_json.read_text()) if vc_json.exists() else {}\n",
    "\n",
    "masked = lambda s: (s[:3] + '***' + s[-2:]) if s and len(s) > 6 else (s or None)\n",
    "print('GRAPH_CLIENT_ID:', masked(creds.graph_client_id))\n",
    "print('GRAPH_TENANT_ID:', masked(creds.graph_tenant_id))\n",
    "print('AZURE_SPEECH_KEY:', masked(creds.azure_speech_key))\n",
    "print('AZURE_SPEECH_REGION:', creds.azure_speech_region or None)\n",
    "print('agent.yml keys:', list(agent_cfg.keys()) if agent_cfg else [])\n",
    "print('verified-credential fields:', list(vc_cfg.keys()) if vc_cfg else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6de8c",
   "metadata": {},
   "source": [
    "## 4) Import TEC Modules and Prompt Templates\n",
    "\n",
    "Expose helpers to list available templates and call the agent runner programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "\n",
    "# prompt_templates.py helper\n",
    "try:\n",
    "    pt = import_module('ai-workflow.prompt_templates')\n",
    "except Exception:\n",
    "    pt = None\n",
    "\n",
    "# tec_agent_runner (CLI-ish module)\n",
    "try:\n",
    "    agent_runner = import_module('tec_agent_runner')\n",
    "except Exception:\n",
    "    agent_runner = None\n",
    "\n",
    "print('prompt_templates available:', bool(pt))\n",
    "print('tec_agent_runner available:', bool(agent_runner))\n",
    "\n",
    "available_templates = []\n",
    "if pt and hasattr(pt, 'TEMPLATES'):\n",
    "    available_templates = list(getattr(pt, 'TEMPLATES').keys())\n",
    "print('Templates:', available_templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e4df7",
   "metadata": {},
   "source": [
    "## 5) Define Lumina Instruction Schema (AM-Class)\n",
    "\n",
    "Pydantic schema to serialize persona, structural rules, command templates, and safety rails (versioned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da57080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "import json, yaml\n",
    "\n",
    "class StructuralRules(BaseModel):\n",
    "    hypothesis_anchoring: bool = True\n",
    "    dual_channel: bool = True\n",
    "    clause_stack: bool = True\n",
    "    neurochem_map: bool = True\n",
    "    cutaway_logic: bool = True\n",
    "    symbolic_recursion: bool = True\n",
    "\n",
    "class CommandTemplate(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    template: str\n",
    "\n",
    "class SafetyRails(BaseModel):\n",
    "    allow_medical_advice: bool = False\n",
    "    allow_financial_advice: bool = False\n",
    "    disallowed_sources: List[str] = Field(default_factory=lambda: [\"reddit-only\", \"x-says\"])  # illustrative\n",
    "\n",
    "class LuminaPersona(BaseModel):\n",
    "    version: str = \"AM-1.0\"\n",
    "    designation: str = \"Lumina — Contextual Research Assistant (AM-Class)\"\n",
    "    traits: List[str] = [\"myth-scientific\", \"scholarly\", \"snappy\", \"precise\"]\n",
    "    anchors: List[str] = [\"Lumina\", \"Kaznak\", \"Karma\", \"Arcadia\"]\n",
    "    structural: StructuralRules = StructuralRules()\n",
    "    commands: List[CommandTemplate] = Field(default_factory=lambda: [\n",
    "        CommandTemplate(\n",
    "            name=\"default-summary\",\n",
    "            description=\"Summarize content in Arcadia’s myth-scientific voice\",\n",
    "            template=\"Working Hypothesis: {hypothesis}\\nScholarly: {scholarly}\\nResonant: {resonant}\\nNeurochemistry: OXY={oxy}, DOP={dop}, ADR={adr}\\nMic-Line: {mic}\"\n",
    "        )\n",
    "    ])\n",
    "    safety: SafetyRails = SafetyRails()\n",
    "\n",
    "persona = LuminaPersona()\n",
    "print(persona.model_dump_json(indent=2))\n",
    "\n",
    "# Save reusable spec for apps/agents\n",
    "spec_path_json = OUTPUT / 'lumina_persona_am.json'\n",
    "spec_path_yaml = OUTPUT / 'lumina_persona_am.yaml'\n",
    "spec_path_json.write_text(persona.model_dump_json(indent=2))\n",
    "spec_path_yaml.write_text(yaml.safe_dump(json.loads(persona.model_dump_json()), sort_keys=False))\n",
    "print('Saved persona spec to:', spec_path_json.name, 'and', spec_path_yaml.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88dc557",
   "metadata": {},
   "source": [
    "## 6) Compile Prompt Stack (System + Persona + Task)\n",
    "\n",
    "Compose chat prompts from policy + persona + task; provide simple renderers for chat APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def compile_chat_messages(persona: LuminaPersona, task: str) -> List[Dict[str,str]]:\n",
    "    system = (\n",
    "        \"You are Lumina (AM-Class), a myth-scientific research assistant. \"\n",
    "        \"Follow the structural rules: Working Hypothesis, dual-channel (scholarly + resonant), \"\n",
    "        \"neurochemical indexing, and close with a mic-line. Maintain TEC cosmology continuity.\"\n",
    "    )\n",
    "    sys_persona = persona.model_dump_json()\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"system\", \"content\": f\"Persona:: {sys_persona}\"},\n",
    "        {\"role\": \"user\", \"content\": task},\n",
    "    ]\n",
    "\n",
    "# quick unit check\n",
    "test_msgs = compile_chat_messages(persona, \"Summarize the resonance of Sleep Token - The Summoning.\")\n",
    "print('Stacked messages:', len(test_msgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea4218",
   "metadata": {},
   "source": [
    "## 7) Context Ingestion from repo\n",
    "\n",
    "Index text from `docs/`, `data/`, and `ai-workflow/output` with provenance tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Tuple\n",
    "\n",
    "def iter_text_files(root: Path, patterns=(\".md\", \".txt\", \".json\")):\n",
    "    for p in root.rglob('*'):\n",
    "        if p.suffix.lower() in patterns and p.is_file():\n",
    "            yield p\n",
    "\n",
    "def load_text_with_provenance(paths: list[Path], max_chars=10000) -> list[dict]:\n",
    "    out = []\n",
    "    for p in paths:\n",
    "        try:\n",
    "            raw = p.read_text(encoding='utf-8', errors='ignore')\n",
    "        except Exception:\n",
    "            continue\n",
    "        txt = re.sub(r\"\\s+\", \" \", raw).strip()\n",
    "        out.append({\"path\": str(p.relative_to(ROOT)), \"preview\": txt[:max_chars]})\n",
    "    return out\n",
    "\n",
    "sources = list(iter_text_files(DOCS)) + list(iter_text_files(DATA)) + list(iter_text_files(AIWF / 'output'))\n",
    "ingest = load_text_with_provenance(sources[:50])  # cap for demo\n",
    "print('Ingested docs (previewed):', len(ingest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a96c7",
   "metadata": {},
   "source": [
    "## 8) Resonance Overlay Scoring\n",
    "\n",
    "$R = w_o OXY + w_d DOP + w_a ADR$ normalized to [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Resonance(NamedTuple):\n",
    "    oxy: float\n",
    "    dop: float\n",
    "    adr: float\n",
    "    score: float\n",
    "\n",
    "def clamp01(x: float) -> float:\n",
    "    return max(0.0, min(1.0, x))\n",
    "\n",
    "def resonance_score(oxy: float, dop: float, adr: float, w=(0.4,0.4,0.2)) -> Resonance:\n",
    "    o, d, a = map(clamp01, (oxy, dop, adr))\n",
    "    s = clamp01(o*w[0] + d*w[1] + a*w[2])\n",
    "    return Resonance(o, d, a, s)\n",
    "\n",
    "print('Resonance demo:', resonance_score(0.8, 0.6, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e7157",
   "metadata": {},
   "source": [
    "## 9) Scheduling Agent (Microsoft Graph, device-code flow)\n",
    "\n",
    "Create/update/list calendar events. Requires `GRAPH_CLIENT_ID` and `GRAPH_TENANT_ID` in `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, time\n",
    "import msal\n",
    "from msgraph import GraphServiceClient\n",
    "try:\n",
    "    from azure.identity import UsernamePasswordCredential  # optional alt flow if needed\n",
    "except Exception:\n",
    "    UsernamePasswordCredential = None\n",
    "\n",
    "DB = OUTPUT / 'schedule_meta.sqlite3'\n",
    "conn = sqlite3.connect(DB)\n",
    "conn.execute(\"CREATE TABLE IF NOT EXISTS events (id TEXT PRIMARY KEY, subject TEXT, when_utc TEXT, created_at TEXT)\")\n",
    "conn.commit()\n",
    "\n",
    "SCOPES = [\"Calendars.ReadWrite\"]\n",
    "CLIENT_ID = creds.graph_client_id\n",
    "TENANT_ID = creds.graph_tenant_id\n",
    "\n",
    "def get_token_device_code() -> str | None:\n",
    "    if not CLIENT_ID or not TENANT_ID:\n",
    "        print('Graph creds missing; skip auth.')\n",
    "        return None\n",
    "    app = msal.PublicClientApplication(CLIENT_ID, authority=f\"https://login.microsoftonline.com/{TENANT_ID}\")\n",
    "    flow = app.initiate_device_flow(scopes=[f\"https://graph.microsoft.com/.default\"])\n",
    "    if 'user_code' not in flow:\n",
    "        print('Failed to create device flow:', flow)\n",
    "        return None\n",
    "    print('Device code:', flow['user_code'])\n",
    "    print('Visit:', flow['verification_uri'])\n",
    "    res = app.acquire_token_by_device_flow(flow)\n",
    "    if 'access_token' in res:\n",
    "        return res['access_token']\n",
    "    print('Auth error:', res)\n",
    "    return None\n",
    "\n",
    "# Lazy client wrapper\n",
    "class GraphClient:\n",
    "    def __init__(self, token: str):\n",
    "        self.token = token\n",
    "        self.client = GraphServiceClient(lambda: {\"Authorization\": f\"Bearer {token}\"})\n",
    "\n",
    "    async def create_event(self, subject: str, start_iso: str, end_iso: str):\n",
    "        body = {\n",
    "            \"subject\": subject,\n",
    "            \"start\": {\"dateTime\": start_iso, \"timeZone\": \"UTC\"},\n",
    "            \"end\": {\"dateTime\": end_iso, \"timeZone\": \"UTC\"}\n",
    "        }\n",
    "        evt = await self.client.me.events.post(body)\n",
    "        conn.execute(\"INSERT OR REPLACE INTO events(id, subject, when_utc, created_at) VALUES(?,?,?,?)\",\n",
    "                     (evt.id, subject, start_iso, datetime.utcnow().isoformat()))\n",
    "        conn.commit()\n",
    "        return evt\n",
    "\n",
    "    async def list_upcoming(self, top=5):\n",
    "        return await self.client.me.calendarview.get(query_parameters={\"top\": top})\n",
    "\n",
    "print('Scheduling DB:', DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e07ea",
   "metadata": {},
   "source": [
    "## 10) Audio Notes: Transcribe (Whisper CPU or Azure Speech)\n",
    "\n",
    "Loads audio from `data/evidence/*.amr|wav`, transcribes locally by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bad381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import glob\n",
    "\n",
    "try:\n",
    "    import whisper\n",
    "except Exception:\n",
    "    whisper = None\n",
    "\n",
    "AUDIO_DIR = DATA / 'evidence'\n",
    "\n",
    "def transcribe_local_whisper(audio_path: Path, model_name='base') -> dict:\n",
    "    if whisper is None:\n",
    "        raise RuntimeError('whisper not installed')\n",
    "    model = whisper.load_model(model_name)\n",
    "    result = model.transcribe(str(audio_path))\n",
    "    return result\n",
    "\n",
    "# Demo discovery only (do not force long jobs)\n",
    "audio_files = [Path(p) for p in glob.glob(str(AUDIO_DIR / '*.amr'))] + [Path(p) for p in glob.glob(str(AUDIO_DIR / '*.wav'))]\n",
    "print('Found audio files:', [p.name for p in audio_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b686f",
   "metadata": {},
   "source": [
    "## 11) Task Queue and Orchestration (asyncio + APScheduler)\n",
    "\n",
    "Minimal async queue and periodic jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from apscheduler.schedulers.asyncio import AsyncIOScheduler\n",
    "\n",
    "queue: asyncio.Queue = asyncio.Queue()\n",
    "\n",
    "async def job_research(payload):\n",
    "    await asyncio.sleep(0.1)\n",
    "    return {\"ok\": True, \"kind\": \"research\", \"payload\": payload}\n",
    "\n",
    "async def worker():\n",
    "    while True:\n",
    "        task = await queue.get()\n",
    "        try:\n",
    "            if task.get('type') == 'research':\n",
    "                res = await job_research(task.get('payload', {}))\n",
    "                print('Job done:', res)\n",
    "        finally:\n",
    "            queue.task_done()\n",
    "\n",
    "scheduler = AsyncIOScheduler()\n",
    "scheduler.add_job(lambda: print('housekeeping tick'), 'interval', seconds=60)\n",
    "scheduler.start()\n",
    "\n",
    "print('Scheduler started. Queue ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00382657",
   "metadata": {},
   "source": [
    "## 12) Integrate `tec_agent_runner`\n",
    "\n",
    "Invoke the agent runner from the notebook, capturing logs to `ai-workflow/output/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, contextlib\n",
    "\n",
    "RUN_LOG = OUTPUT / f\"agent_run_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "\n",
    "def run_agent_from_notebook(manifest_path: Path | None = None):\n",
    "    if agent_runner is None:\n",
    "        print('tec_agent_runner not importable')\n",
    "        return None\n",
    "    argv = []\n",
    "    if manifest_path:\n",
    "        argv += [\"--manifest\", str(manifest_path)]\n",
    "    buf = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):\n",
    "        try:\n",
    "            if hasattr(agent_runner, 'main'):\n",
    "                agent_runner.main(argv)\n",
    "            else:\n",
    "                print('No main() in tec_agent_runner')\n",
    "        except SystemExit:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print('run error:', e)\n",
    "    RUN_LOG.write_text(buf.getvalue())\n",
    "    print('Wrote run log:', RUN_LOG.name)\n",
    "\n",
    "# Example (commented):\n",
    "# run_agent_from_notebook(ROOT / 'agents' / 'manifests' / 'airth_research_guard.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599fca81",
   "metadata": {},
   "source": [
    "## 13) Persist Outputs to `ai-workflow/output` and `docs/exports`\n",
    "\n",
    "Write compiled prompts, transcripts, resonance reports, and schedule receipts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca92969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import json\n",
    "\n",
    "EXPORTS = DOCS / 'exports'\n",
    "EXPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_json(obj: dict, name: str, outdir: Path = OUTPUT) -> Path:\n",
    "    p = outdir / name\n",
    "    p.write_text(json.dumps(obj, indent=2, ensure_ascii=False))\n",
    "    return p\n",
    "\n",
    "def daily_summary_path(stem: str) -> Path:\n",
    "    return EXPORTS / f\"{stem}_{date.today().isoformat()}.json\"\n",
    "\n",
    "print('Exports dir:', EXPORTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b8f2f",
   "metadata": {},
   "source": [
    "## 14) Run Unit Tests with pytest\n",
    "\n",
    "Runs repo tests and emits JUnit XML to `docs/exports/test-results.xml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "XML_OUT = EXPORTS / 'test-results.xml'\n",
    "print('Running pytest...')\n",
    "!pytest -q --junitxml \"{XML_OUT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c816cb",
   "metadata": {},
   "source": [
    "## 15) End-to-End Demo (prompt → research → schedule → transcript → report)\n",
    "\n",
    "This cell demonstrates a stitched flow using previously defined helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, random\n",
    "\n",
    "async def demo_flow():\n",
    "    # 1) Persona + prompt stack\n",
    "    task = \"Summarize TEC Codex resonance of recent docs and propose next 1 appointment to improve stability.\"\n",
    "    msgs = compile_chat_messages(persona, task)\n",
    "\n",
    "    # 2) Ingest a few docs\n",
    "    ctx = ingest[:5]\n",
    "\n",
    "    # 3) Compute resonance for a fake feature vector\n",
    "    r = resonance_score(random.random(), random.random(), random.random())\n",
    "\n",
    "    # 4) (Optional) schedule event via Graph — only if token obtained\n",
    "    token = None  # set via get_token_device_code() if you want to run it live\n",
    "    created_event = None\n",
    "    # token = get_token_device_code()\n",
    "    # if token:\n",
    "    #     gc = GraphClient(token)\n",
    "    #     now = datetime.utcnow()\n",
    "    #     start = (now.replace(microsecond=0)).isoformat() + 'Z'\n",
    "    #     end = (now.replace(microsecond=0)).isoformat() + 'Z'\n",
    "    #     created_event = await gc.create_event('TEC Health Check', start, end)\n",
    "\n",
    "    # 5) Transcribe first audio (if any) — skip heavy run by default\n",
    "    transcript = {\"skipped\": True}\n",
    "    # if audio_files:\n",
    "    #     transcript = transcribe_local_whisper(audio_files[0])\n",
    "\n",
    "    report = {\n",
    "        \"messages\": msgs,\n",
    "        \"context_sample\": ctx,\n",
    "        \"resonance\": {\"oxy\": r.oxy, \"dop\": r.dop, \"adr\": r.adr, \"score\": r.score},\n",
    "        \"scheduled\": bool(created_event),\n",
    "        \"transcript_meta\": list(map(lambda p: p.name, audio_files))[:3],\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "    }\n",
    "    p = save_json(report, 'demo_report.json')\n",
    "    print('Saved demo_report:', p)\n",
    "\n",
    "# To run the demo, uncomment:\n",
    "# await demo_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe849365",
   "metadata": {},
   "source": [
    "## Call LUMINAI_API_URL (WordPress agent) — Example\n",
    "\n",
    "Reads `LUMINAI_API_URL` from environment and posts a simple message array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, httpx, json\n",
    "\n",
    "LUMINAI_API_URL = os.getenv('LUMINAI_API_URL', '').strip() or None\n",
    "print('LUMINAI_API_URL:', 'set' if LUMINAI_API_URL else 'not set')\n",
    "\n",
    "async def call_wp_agent(prompt: str) -> dict:\n",
    "    if not LUMINAI_API_URL:\n",
    "        return {\"error\": \"LUMINAI_API_URL not set\"}\n",
    "    payload = {\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        r = await client.post(LUMINAI_API_URL, json=payload)\n",
    "        try:\n",
    "            return r.json()\n",
    "        except Exception:\n",
    "            return {\"status\": r.status_code, \"text\": r.text[:500]}\n",
    "\n",
    "# Example (commented to avoid accidental external call):\n",
    "# resp = await call_wp_agent('Hello Lumina, quick resonance check on today\\'s plan.')\n",
    "# print(resp)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
